{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterorogeneous graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Node(s) add + delete\n",
    "- Edge(s) add + delete\n",
    "- Feature(s) add + delete in some nodes and edges -\n",
    "graph is heterogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.datasets import AMiner\n",
    "\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mauthor\u001b[0m={\n",
      "    y=[246678],\n",
      "    y_index=[246678],\n",
      "    num_nodes=1693531\n",
      "  },\n",
      "  \u001b[1mvenue\u001b[0m={\n",
      "    y=[134],\n",
      "    y_index=[134],\n",
      "    num_nodes=3883\n",
      "  },\n",
      "  \u001b[1mpaper\u001b[0m={ num_nodes=3194405 },\n",
      "  \u001b[1m(paper, written_by, author)\u001b[0m={ edge_index=[2, 9323605] },\n",
      "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 9323605] },\n",
      "  \u001b[1m(paper, published_in, venue)\u001b[0m={ edge_index=[2, 3194405] },\n",
      "  \u001b[1m(venue, publishes, paper)\u001b[0m={ edge_index=[2, 3194405] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The heterogeneous AMiner dataset from the “metapath2vec: Scalable Representation Learning for Heterogeneous Networks” paper, \n",
    "consisting of nodes from type \"paper\", \"author\" and \"venue\". Venue categories and author research interests are available as \n",
    "ground truth labels for a subset of nodes.\n",
    "\n",
    "Class https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/aminer.html?highlight=y_index#\n",
    "\"\"\"\n",
    "\n",
    "dataset_het = AMiner(root=r\"./AMiner2\")\n",
    "data_het = dataset_het[0]\n",
    "\n",
    "data_het.keys #['y_index', 'y', 'edge_index', 'num_nodes']\n",
    "print(data_het)\n",
    "\n",
    "pp = data_het.edge_index_dict\n",
    "num_edges = data_het.num_edges\n",
    "node_store = data_het.get_node_store('paper')\n",
    "node_types = data_het.node_types\n",
    "edge_store = data_het.get_edge_store('author', 'writes', 'paper')\n",
    "edge_types = data_het.edge_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246678"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"author\"].y_index # author id\n",
    "len(data_het[\"author\"].y) # author features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"venue\"].y_index # venue id\n",
    "data_het[\"venue\"].y # venue features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNode(data, type, add_edge=True):\n",
    "    \"\"\"\n",
    "    data - het data\n",
    "    type - \"venue\" or \"author\", dtype=string\n",
    "    add_edge=True if you want to add edge\n",
    "    \"\"\"\n",
    "    new_id = random.randint(900000, 10000000) # to y_index\n",
    "    new_type = random.randint(0, 7) # to y\n",
    "    paper_id = random.randint(0, 3194404)\n",
    "\n",
    "    # data[type].y_index = data[type].y_index.cpu().detach().numpy();\n",
    "    # data[type].y = data[type].y.cpu().detach().numpy();\n",
    "    \n",
    "    data[type].y_index = np.append(data[type].y_index, new_id)\n",
    "    data[type].y = np.append(data[type].y, new_type)\n",
    "\n",
    "    if type == \"author\":\n",
    "        data['author', 'writes', 'paper'].edge_index.cpu().detach().numpy();\n",
    "        data[\"paper\", \"written_by\", \"author\"].edge_index.cpu().detach().numpy();\n",
    "\n",
    "        left = np.append(data['author', 'writes', 'paper'].edge_index[0], new_id)\n",
    "        right = np.append(data['author', 'writes', 'paper'].edge_index[1], paper_id)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data['author', 'writes', 'paper'].edge_index = new\n",
    "\n",
    "        left = np.append(data[\"paper\", \"written_by\", \"author\"].edge_index[0], paper_id)\n",
    "        right = np.append(data[\"paper\", \"written_by\", \"author\"].edge_index[1], new_id)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"written_by\", \"author\"].edge_index = new\n",
    "\n",
    "    if type == \"venue\":\n",
    "        data[\"paper\", \"published_in\", \"venue\"].edge_index.cpu().detach().numpy();\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index.cpu().detach().numpy();\n",
    "\n",
    "        left = np.append(data[\"venue\", \"publishes\", \"paper\"].edge_index[0], new_id)\n",
    "        right = np.append(data[\"venue\", \"publishes\", \"paper\"].edge_index[1], paper_id)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index = new\n",
    "\n",
    "        left = np.append(data[\"paper\", \"published_in\", \"venue\"].edge_index[0], paper_id)\n",
    "        right = np.append(data[\"paper\", \"published_in\", \"venue\"].edge_index[1], new_id)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index = new\n",
    "    return\n",
    "# print(len(data_het[\"venue\"].y))    \n",
    "# addNode(data_het, type=\"venue\")\n",
    "# print(len(data_het[\"venue\"].y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246672\n",
      "9323571\n",
      "9323571\n",
      "After\n",
      "246671\n",
      "9323559\n",
      "9323559\n"
     ]
    }
   ],
   "source": [
    "def delNode(data, type, del_edge=True):\n",
    "    \"\"\"\n",
    "    Delete a random node of a certain type\n",
    "    :input:\n",
    "        data - het data\n",
    "        type - \"venue\", \"paper\" or \"author\", dtype=string\n",
    "        del_edge=True if you want to delete an edge\n",
    "    :output: data object modified\n",
    "    \"\"\"\n",
    "    # for edge deletion\n",
    "    awp = data['author', 'writes', 'paper'].edge_index.cpu().detach().numpy();\n",
    "    pwa = data[\"paper\", \"written_by\", \"author\"].edge_index.cpu().detach().numpy();\n",
    "    ppv = data[\"paper\", \"published_in\", \"venue\"].edge_index.cpu().detach().numpy();\n",
    "    vpp = data[\"venue\", \"publishes\", \"paper\"].edge_index.cpu().detach().numpy();\n",
    "    \n",
    "    # Author\n",
    "    if type == \"author\":\n",
    "        node_index = random.randint(0, len(data[\"author\"].y))\n",
    "        data[type].y_index = np.delete(data[type].y_index, node_index)\n",
    "        data[type].y = np.delete(data[type].y, node_index)\n",
    "        id = (data[type].y_index)[node_index]\n",
    "\n",
    "        if del_edge == True:\n",
    "            to_delete = []\n",
    "            for i in range(len(awp[0])):\n",
    "                if awp[0][i] == id:\n",
    "                    to_delete.append(i)\n",
    "            left = np.delete(awp[0], to_delete)\n",
    "            right = np.delete(awp[1], to_delete)\n",
    "            new = torch.tensor(np.stack([left, right]))\n",
    "            data['author', 'writes', 'paper'].edge_index = new\n",
    "\n",
    "            to_delete = []\n",
    "            for i in range(len(pwa[1])):\n",
    "                if pwa[1][i] == id:\n",
    "                    to_delete.append(i)\n",
    "\n",
    "            left = np.delete(pwa[0], to_delete)\n",
    "            right = np.delete(pwa[1], to_delete)\n",
    "            new = torch.tensor(np.stack([left, right]))\n",
    "            data[\"paper\", \"written_by\", \"author\"].edge_index = new       \n",
    "\n",
    "    # Venue\n",
    "    if type == \"venue\":\n",
    "        node_index = random.randint(0, len(data[\"venue\"].y))\n",
    "        data[type].y_index = np.delete(data[type].y_index, node_index)\n",
    "        data[type].y = np.delete(data[type].y, node_index)\n",
    "        id = (data[type].y_index)[node_index]\n",
    "\n",
    "        if del_edge==True:\n",
    "            to_delete = []\n",
    "            for i in range(len(ppv[0])):\n",
    "                if ppv[1][i] == id:\n",
    "                    to_delete.append(i)\n",
    "            left = np.delete(ppv[0], to_delete)\n",
    "            right = np.delete(ppv[1], to_delete)\n",
    "            new = torch.tensor(np.stack([left, right]))\n",
    "            data[\"paper\", \"published_in\", \"venue\"].edge_index = new  \n",
    "\n",
    "\n",
    "            to_delete = []\n",
    "            for i in range(len(vpp[1])):\n",
    "                if vpp[0][i] == id:\n",
    "                    to_delete.append(i)\n",
    "            left = np.delete(vpp[0], to_delete)\n",
    "            right = np.delete(vpp[1], to_delete)\n",
    "            new = torch.tensor(np.stack([left, right]))\n",
    "            data[\"venue\", \"publishes\", \"paper\"].edge_index = new      \n",
    "        \n",
    "    # Paper    \n",
    "    if type == \"paper\":\n",
    "        id = random.randint(0, data_het[type][\"num_nodes\"])\n",
    "\n",
    "        # Author\n",
    "        to_delete = []\n",
    "        for i in range(len(awp[1])):\n",
    "            if awp[1][i] == id:\n",
    "                to_delete.append(i)\n",
    "        left = np.delete(awp[0], to_delete)\n",
    "        right = np.delete(awp[1], to_delete)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data['author', 'writes', 'paper'].edge_index = new\n",
    "\n",
    "        to_delete = []\n",
    "        for i in range(len(pwa[0])):\n",
    "            if pwa[0][i] == id:\n",
    "                to_delete.append(i)\n",
    "\n",
    "        left = np.delete(pwa[0], to_delete)\n",
    "        right = np.delete(pwa[1], to_delete)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"written_by\", \"author\"].edge_index = new \n",
    "        \n",
    "        # Venue\n",
    "        to_delete = []\n",
    "        for i in range(len(ppv[0])):\n",
    "            if ppv[0][i] == id:\n",
    "                to_delete.append(i)\n",
    "        left = np.delete(ppv[0], to_delete)\n",
    "        right = np.delete(ppv[1], to_delete)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"published_in\", \"venue\"].edge_index = new  \n",
    "\n",
    "        to_delete = []\n",
    "        for i in range(len(vpp[1])):\n",
    "            if vpp[1][i] == id:\n",
    "                to_delete.append(i)\n",
    "        left = np.delete(vpp[0], to_delete)\n",
    "        right = np.delete(vpp[1], to_delete)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index = new     \n",
    "    return\n",
    "\n",
    "print(len(data_het[\"author\"].y_index))\n",
    "print(len(data_het[\"paper\", \"written_by\", \"author\"].edge_index[0]))\n",
    "print(len(data_het[\"paper\", \"written_by\", \"author\"].edge_index[1]))\n",
    "delNode(data_het, type=\"author\")\n",
    "print(\"After\")\n",
    "print(len(data_het[\"author\"].y_index))\n",
    "print(len(data_het[\"paper\", \"written_by\", \"author\"].edge_index[0]))\n",
    "print(len(data_het[\"paper\", \"written_by\", \"author\"].edge_index[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3194405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"paper\"][\"num_nodes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246678"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"author\"].y_index # author id\n",
    "data_het[\"author\"].y # author features\n",
    "len(data_het[\"author\"].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mauthor\u001b[0m={\n",
       "    y=[246678],\n",
       "    y_index=[246678],\n",
       "    num_nodes=1693531\n",
       "  },\n",
       "  \u001b[1mvenue\u001b[0m={\n",
       "    y=[134],\n",
       "    y_index=[134],\n",
       "    num_nodes=3883\n",
       "  },\n",
       "  \u001b[1mpaper\u001b[0m={ num_nodes=3194405 },\n",
       "  \u001b[1m(paper, written_by, author)\u001b[0m={ edge_index=[2, 9323605] },\n",
       "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 9323605] },\n",
       "  \u001b[1m(paper, published_in, venue)\u001b[0m={ edge_index=[2, 3194405] },\n",
       "  \u001b[1m(venue, publishes, paper)\u001b[0m={ edge_index=[2, 3194405] }\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1741, 2245,  111,  837, 2588, 2116, 2696, 3648, 3784,  313, 3414,  598,\n",
       "        2995, 2716, 1423,  783, 1902, 3132, 1753, 2748, 2660, 3182,  775, 3339,\n",
       "        1601, 3589,  156, 1145,  692, 3048,  925, 1587,  820, 1374, 3719,  819,\n",
       "         492, 3830, 2777, 3001, 3693,  517, 1808, 2353, 3499, 1763, 2372, 1030,\n",
       "         721, 2680, 3355, 1217, 3400, 1271, 1970, 1127,  407,  353, 1471, 1095,\n",
       "         477, 3701,   65, 1009, 1899, 1442, 2073, 3143, 2466,  289, 1996, 1070,\n",
       "        3871, 3695,  281, 3633,   50, 2642, 1925, 1285, 2587, 3814, 3582, 1873,\n",
       "        1339, 3450,  271, 2966,  453, 2638, 1354, 3211,  391, 1588, 3875, 2216,\n",
       "        2146, 3765, 2486,  661, 3367,  426,  750, 2158,  519,  230, 1677,  839,\n",
       "        2945, 1313, 1037, 2879, 2225, 3523, 1247,  448,  227, 3385,  529, 2849,\n",
       "        1584, 1229,  373, 2235, 1819, 1764, 3155, 2852, 2789, 3474, 1571, 2088,\n",
       "         208,  462])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"venue\"].y_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 5,  ..., 0, 1, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"author\"].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node types:  ['author', 'venue', 'paper']\n",
      "Edge types:  [('paper', 'written_by', 'author'), ('author', 'writes', 'paper'), ('paper', 'published_in', 'venue'), ('venue', 'publishes', 'paper')]\n"
     ]
    }
   ],
   "source": [
    "node_types, edge_types = data_het.metadata()\n",
    "print(\"Node types: \", node_types)\n",
    "print(\"Edge types: \", edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delType(data, type):\n",
    "    \"\"\"\n",
    "    input: data - heterog data\n",
    "           type - node type or edge type dtype=string\n",
    "\n",
    "           del data['venue']  # Deleting 'field_of_study' node type\n",
    "           del data['writes']       # Deleting 'has_topic' edge type    \n",
    "    \"\"\"\n",
    "    node_types, edge_types = data.metadata()\n",
    "    print(\"Before: \")\n",
    "    print(\"Node types: \", node_types)\n",
    "    print(\"Edge types: \", edge_types)\n",
    "    del data[type]       # Deleting edge type\n",
    "    node_types, edge_types = data.metadata()\n",
    "    print(\"After: \")\n",
    "    print(\"Node types: \", node_types)\n",
    "    print(\"Edge types: \", edge_types)\n",
    "    return\n",
    "\n",
    "# delType(data_het, \"venue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_stores = data_het.edge_stores\n",
    "edge_stores\n",
    "len(edge_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: \n",
      "Node types:  ['author', 'venue', 'paper']\n",
      "Edge types:  [('paper', 'written_by', 'author'), ('author', 'writes', 'paper'), ('paper', 'published_in', 'venue'), ('venue', 'publishes', 'paper')]\n"
     ]
    }
   ],
   "source": [
    "node_types, edge_types = data_het.metadata()\n",
    "print(\"After: \")\n",
    "print(\"Node types: \", node_types)\n",
    "print(\"Edge types: \", edge_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcac22119d5d3fe9b7808e8a2b2b1fad943735cdeeeffec737ec21b4dfa5d54e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
