{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneous graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Node(s) add + delete\n",
    "- Edge(s) add + delete\n",
    "- Feature(s) add + delete in some nodes and edges -\n",
    "graph is heterogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.datasets import AMiner\n",
    "\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mauthor\u001b[0m={\n",
      "    y=[246678],\n",
      "    y_index=[246678],\n",
      "    num_nodes=1693531\n",
      "  },\n",
      "  \u001b[1mvenue\u001b[0m={\n",
      "    y=[134],\n",
      "    y_index=[134],\n",
      "    num_nodes=3883\n",
      "  },\n",
      "  \u001b[1mpaper\u001b[0m={ num_nodes=3194405 },\n",
      "  \u001b[1m(paper, written_by, author)\u001b[0m={ edge_index=[2, 9323605] },\n",
      "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 9323605] },\n",
      "  \u001b[1m(paper, published_in, venue)\u001b[0m={ edge_index=[2, 3194405] },\n",
      "  \u001b[1m(venue, publishes, paper)\u001b[0m={ edge_index=[2, 3194405] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The heterogeneous AMiner dataset from the “metapath2vec: Scalable Representation Learning for Heterogeneous Networks” paper, \n",
    "consisting of nodes from type \"paper\", \"author\" and \"venue\". Venue categories and author research interests are available as \n",
    "ground truth labels for a subset of nodes.\n",
    "\n",
    "Class https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/aminer.html?highlight=y_index#\n",
    "\"\"\"\n",
    "\n",
    "dataset_het = AMiner(root=r\"./AMiner2\")\n",
    "data_het = dataset_het[0]\n",
    "\n",
    "data_het.keys #['y_index', 'y', 'edge_index', 'num_nodes']\n",
    "print(data_het)\n",
    "\n",
    "pp = data_het.edge_index_dict\n",
    "num_edges = data_het.num_edges\n",
    "node_store = data_het.get_node_store('paper')\n",
    "node_types = data_het.node_types\n",
    "edge_store = data_het.get_edge_store('author', 'writes', 'paper')\n",
    "edge_types = data_het.edge_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246678"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"author\"].y_index # author id\n",
    "len(data_het[\"author\"].y) # author features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"venue\"].y_index # venue id\n",
    "data_het[\"venue\"].y # venue features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delType(data, type):\n",
    "    \"\"\"\n",
    "    input: data - heterog data\n",
    "           type - node type or edge type dtype=string\n",
    "\n",
    "           del data['venue']  # Deleting 'field_of_study' node type\n",
    "           del data['writes']       # Deleting 'has_topic' edge type    \n",
    "    \"\"\"\n",
    "    node_types, edge_types = data.metadata()\n",
    "    print(\"Before: \")\n",
    "    print(\"Node types: \", node_types)\n",
    "    print(\"Edge types: \", edge_types)\n",
    "    del data[type]       # Deleting edge type\n",
    "    node_types, edge_types = data.metadata()\n",
    "    print(\"After: \")\n",
    "    print(\"Node types: \", node_types)\n",
    "    print(\"Edge types: \", edge_types)\n",
    "    return\n",
    "\n",
    "# delType(data_het, \"venue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNode(data, type, add_edge=True):\n",
    "    \"\"\"\n",
    "    data - het data\n",
    "    type - \"venue\" or \"author\", dtype=string\n",
    "    add_edge=True if you want to add edge\n",
    "    \"\"\"\n",
    "    new_id = random.randint(900000, 10000000) # to y_index\n",
    "    new_type = random.randint(0, 7) # to y\n",
    "    paper_id = random.randint(0, 3194404)\n",
    "    \n",
    "    data[type].y_index = np.append(data[type].y_index, new_id)\n",
    "    data[type].y = np.append(data[type].y, new_type)\n",
    "\n",
    "    if type == \"author\":\n",
    "        data['author', 'writes', 'paper'].edge_index.cpu().detach().numpy();\n",
    "        data[\"paper\", \"written_by\", \"author\"].edge_index.cpu().detach().numpy();\n",
    "\n",
    "        left = np.append(data['author', 'writes', 'paper'].edge_index[0], new_id)\n",
    "        right = np.append(data['author', 'writes', 'paper'].edge_index[1], paper_id)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data['author', 'writes', 'paper'].edge_index = new\n",
    "\n",
    "        left = np.append(data[\"paper\", \"written_by\", \"author\"].edge_index[0], paper_id)\n",
    "        right = np.append(data[\"paper\", \"written_by\", \"author\"].edge_index[1], new_id)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"written_by\", \"author\"].edge_index = new\n",
    "\n",
    "    if type == \"venue\":\n",
    "        data[\"paper\", \"published_in\", \"venue\"].edge_index.cpu().detach().numpy();\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index.cpu().detach().numpy();\n",
    "\n",
    "        left = np.append(data[\"venue\", \"publishes\", \"paper\"].edge_index[0], new_id)\n",
    "        right = np.append(data[\"venue\", \"publishes\", \"paper\"].edge_index[1], paper_id)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index = new\n",
    "\n",
    "        left = np.append(data[\"paper\", \"published_in\", \"venue\"].edge_index[0], paper_id)\n",
    "        right = np.append(data[\"paper\", \"published_in\", \"venue\"].edge_index[1], new_id)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index = new\n",
    "    return\n",
    "# print(len(data_het[\"venue\"].y))    \n",
    "# addNode(data_het, type=\"venue\")\n",
    "# print(len(data_het[\"venue\"].y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delNode(data, type, del_edge=True):\n",
    "    \"\"\"\n",
    "    Delete a random node of a certain type\n",
    "    :input:\n",
    "        data - het data\n",
    "        type - \"venue\", \"paper\" or \"author\", dtype=string\n",
    "        del_edge=True if you want to delete an edge\n",
    "    :output: data object modified\n",
    "    \"\"\"\n",
    "    # for edge deletion\n",
    "    awp = data['author', 'writes', 'paper'].edge_index.cpu().detach().numpy();\n",
    "    pwa = data[\"paper\", \"written_by\", \"author\"].edge_index.cpu().detach().numpy();\n",
    "    ppv = data[\"paper\", \"published_in\", \"venue\"].edge_index.cpu().detach().numpy();\n",
    "    vpp = data[\"venue\", \"publishes\", \"paper\"].edge_index.cpu().detach().numpy();\n",
    "    \n",
    "    # Author\n",
    "    if type == \"author\":\n",
    "        node_index = random.randint(0, len(data[\"author\"].y))\n",
    "        data[type].y_index = np.delete(data[type].y_index, node_index)\n",
    "        data[type].y = np.delete(data[type].y, node_index)\n",
    "        id = (data[type].y_index)[node_index]\n",
    "\n",
    "        if del_edge == True:\n",
    "            to_delete = []\n",
    "            for i in range(len(awp[0])):\n",
    "                if awp[0][i] == id:\n",
    "                    to_delete.append(i)\n",
    "            left = np.delete(awp[0], to_delete)\n",
    "            right = np.delete(awp[1], to_delete)\n",
    "            new = torch.tensor(np.stack([left, right]))\n",
    "            data['author', 'writes', 'paper'].edge_index = new\n",
    "\n",
    "            to_delete = []\n",
    "            for i in range(len(pwa[1])):\n",
    "                if pwa[1][i] == id:\n",
    "                    to_delete.append(i)\n",
    "\n",
    "            left = np.delete(pwa[0], to_delete)\n",
    "            right = np.delete(pwa[1], to_delete)\n",
    "            new = torch.tensor(np.stack([left, right]))\n",
    "            data[\"paper\", \"written_by\", \"author\"].edge_index = new       \n",
    "\n",
    "    # Venue\n",
    "    if type == \"venue\":\n",
    "        node_index = random.randint(0, len(data[\"venue\"].y))\n",
    "        data[type].y_index = np.delete(data[type].y_index, node_index)\n",
    "        data[type].y = np.delete(data[type].y, node_index)\n",
    "        id = (data[type].y_index)[node_index]\n",
    "\n",
    "        if del_edge==True:\n",
    "            to_delete = []\n",
    "            for i in range(len(ppv[0])):\n",
    "                if ppv[1][i] == id:\n",
    "                    to_delete.append(i)\n",
    "            left = np.delete(ppv[0], to_delete)\n",
    "            right = np.delete(ppv[1], to_delete)\n",
    "            new = torch.tensor(np.stack([left, right]))\n",
    "            data[\"paper\", \"published_in\", \"venue\"].edge_index = new  \n",
    "\n",
    "\n",
    "            to_delete = []\n",
    "            for i in range(len(vpp[1])):\n",
    "                if vpp[0][i] == id:\n",
    "                    to_delete.append(i)\n",
    "            left = np.delete(vpp[0], to_delete)\n",
    "            right = np.delete(vpp[1], to_delete)\n",
    "            new = torch.tensor(np.stack([left, right]))\n",
    "            data[\"venue\", \"publishes\", \"paper\"].edge_index = new      \n",
    "        \n",
    "    # Paper    \n",
    "    if type == \"paper\":\n",
    "        id = random.randint(0, data_het[type][\"num_nodes\"])\n",
    "\n",
    "        # Author\n",
    "        to_delete = []\n",
    "        for i in range(len(awp[1])):\n",
    "            if awp[1][i] == id:\n",
    "                to_delete.append(i)\n",
    "        left = np.delete(awp[0], to_delete)\n",
    "        right = np.delete(awp[1], to_delete)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data['author', 'writes', 'paper'].edge_index = new\n",
    "\n",
    "        to_delete = []\n",
    "        for i in range(len(pwa[0])):\n",
    "            if pwa[0][i] == id:\n",
    "                to_delete.append(i)\n",
    "\n",
    "        left = np.delete(pwa[0], to_delete)\n",
    "        right = np.delete(pwa[1], to_delete)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"written_by\", \"author\"].edge_index = new \n",
    "        \n",
    "        # Venue\n",
    "        to_delete = []\n",
    "        for i in range(len(ppv[0])):\n",
    "            if ppv[0][i] == id:\n",
    "                to_delete.append(i)\n",
    "        left = np.delete(ppv[0], to_delete)\n",
    "        right = np.delete(ppv[1], to_delete)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"published_in\", \"venue\"].edge_index = new  \n",
    "\n",
    "        to_delete = []\n",
    "        for i in range(len(vpp[1])):\n",
    "            if vpp[1][i] == id:\n",
    "                to_delete.append(i)\n",
    "        left = np.delete(vpp[0], to_delete)\n",
    "        right = np.delete(vpp[1], to_delete)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index = new     \n",
    "    return\n",
    "\n",
    "# print(len(data_het[\"author\"].y_index))\n",
    "# print(len(data_het[\"paper\", \"written_by\", \"author\"].edge_index[0]))\n",
    "# print(len(data_het[\"paper\", \"written_by\", \"author\"].edge_index[1]))\n",
    "# delNode(data_het, type=\"author\")\n",
    "# print(\"After\")\n",
    "# print(len(data_het[\"author\"].y_index))\n",
    "# print(len(data_het[\"paper\", \"written_by\", \"author\"].edge_index[0]))\n",
    "# print(len(data_het[\"paper\", \"written_by\", \"author\"].edge_index[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       0,       0,  ..., 1693528, 1693529, 1693530],\n",
       "        [      0,   45988,  124807,  ..., 3194371, 3194387, 3194389]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_het[\"author\", \"writes\", \"paper\"].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addEdge(data, type):\n",
    "    \"\"\"\n",
    "    Add an edge of a certain type\n",
    "    :input:\n",
    "        data - het data\n",
    "        type - one of edge types of AMiner, dtype=string, ex: '\"paper\", \"written_by\", \"author\"'\n",
    "        del_edge=True if you want to delete an edge\n",
    "    :output: data edges of a sertain type modified\n",
    "    \"\"\"\n",
    "    id_paper = random.randint(0, data_het[\"paper\"][\"num_nodes\"])\n",
    "\n",
    "    if type == '\"author\", \"writes\", \"paper\"' or type=='\"paper\", \"written_by\", \"author\"':\n",
    "        awp = data[\"author\", \"writes\", \"paper\"].edge_index.cpu().detach().numpy();\n",
    "        pwa = data[\"paper\", \"written_by\", \"author\"].edge_index.cpu().detach().numpy();\n",
    "        id_idx = random.randint(0, len(data[\"author\"]))\n",
    "        id = data[\"author\"].y_index[id_idx]\n",
    "\n",
    "        left = np.append(awp[0], id)\n",
    "        right = np.append(awp[1], id_paper)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"author\", \"writes\", \"paper\"].edge_index = new\n",
    "\n",
    "        right = np.append(pwa[1], id)\n",
    "        left = np.append(pwa[0], id_paper)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"written_by\", \"author\"].edge_index = new\n",
    "\n",
    "    if type == '\"paper\", \"published_in\", \"venue\"' or type == '\"venue\", \"publishes\", \"paper\"':\n",
    "        ppv = data[\"paper\", \"published_in\", \"venue\"].edge_index.cpu().detach().numpy();\n",
    "        vpp = data[\"venue\", \"publishes\", \"paper\"].edge_index.cpu().detach().numpy();\n",
    "        id_idx = random.randint(0, len(data[\"venue\"]))\n",
    "        id = data[\"venue\"].y_index[id_idx]\n",
    "\n",
    "        right = np.append(ppv[1], id)\n",
    "        left = np.append(ppv[0], id_paper)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"published_in\", \"venue\"].edge_index = new\n",
    "\n",
    "        left = np.append(vpp[0], id)\n",
    "        right = np.append(vpp[1], id_paper)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index = new\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delEdge(data, type):\n",
    "    \"\"\"\n",
    "    Delete the last edge in edges of a certain type\n",
    "    :input:\n",
    "        data - het data\n",
    "        type - one of edge types of AMiner, dtype=string, ex: '\"paper\", \"written_by\", \"author\"'\n",
    "    :output: data edges of a sertain type modified\n",
    "    \"\"\"\n",
    "    if type == '\"author\", \"writes\", \"paper\"':\n",
    "        awp = data[\"author\", \"writes\", \"paper\"].edge_index.cpu().detach().numpy();\n",
    "        left = np.delete(awp[0], -1)\n",
    "        right = np.delete(awp[1], -1)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"author\", \"writes\", \"paper\"].edge_index = new\n",
    "\n",
    "    if type == '\"paper\", \"written_by\", \"author\"':\n",
    "        pwa = data[\"paper\", \"written_by\", \"author\"].edge_index.cpu().detach().numpy();\n",
    "        right = np.delete(pwa[1], -1)\n",
    "        left = np.delete(pwa[0], -1)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"written_by\", \"author\"].edge_index = new\n",
    "\n",
    "    if type == '\"paper\", \"published_in\", \"venue\"':\n",
    "        ppv = data[\"paper\", \"published_in\", \"venue\"].edge_index.cpu().detach().numpy();\n",
    "\n",
    "        right = np.delete(ppv[1], -1)\n",
    "        left = np.delete(ppv[0], -1)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"paper\", \"published_in\", \"venue\"].edge_index = new\n",
    "\n",
    "    if type == '\"venue\", \"publishes\", \"paper\"':\n",
    "        vpp = data[\"venue\", \"publishes\", \"paper\"].edge_index.cpu().detach().numpy();\n",
    "        left = np.delete(vpp[0], -1)\n",
    "        right = np.delete(vpp[1], -1)\n",
    "        new = torch.tensor(np.stack([left, right]))\n",
    "        data[\"venue\", \"publishes\", \"paper\"].edge_index = new\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3, 2, 6],\n",
      "        [2, 5, 6, 4],\n",
      "        [5, 0, 5, 6],\n",
      "        ...,\n",
      "        [0, 6, 5, 5],\n",
      "        [1, 4, 4, 1],\n",
      "        [5, 2, 0, 0]])\n",
      "torch.Size([246678, 4])\n",
      "tensor([[0, 3, 2, 6, 4],\n",
      "        [2, 5, 6, 4, 1],\n",
      "        [5, 0, 5, 6, 0],\n",
      "        ...,\n",
      "        [0, 6, 5, 5, 0],\n",
      "        [1, 4, 4, 1, 6],\n",
      "        [5, 2, 0, 0, 3]])\n",
      "torch.Size([246678, 5])\n"
     ]
    }
   ],
   "source": [
    "def addFeature(data, type):\n",
    "    \"\"\"\n",
    "    Add feature to .y tensor. New tensor [num_nodes, num_node_features]\n",
    "    :input:\n",
    "        data - het data\n",
    "        type - one of node types of AMiner, dtype=string, ex: \"author\"\n",
    "    :output: data nodes .y of a sertain type modified\n",
    "    \"\"\"\n",
    "    if type == \"author\":\n",
    "        a_features = data[\"author\"].y.cpu().detach().numpy();\n",
    "        new_feature_vec = np.random.randint(0,7,a_features.shape[0], dtype='int64')\n",
    "        try:\n",
    "            new_y = np.stack((a_features, new_feature_vec), axis=1)\n",
    "        except:\n",
    "            new_y = np.concatenate((a_features, np.array([new_feature_vec]).T), axis=1)\n",
    "\n",
    "        data[\"author\"].y = torch.tensor(new_y)\n",
    "\n",
    "    if type == \"venue\":\n",
    "        v_features = data[\"venue\"].y.cpu().detach().numpy();\n",
    "        new_feature_vec = np.random.randint(0,7,v_features.shape[0], dtype='int64')\n",
    "        try:\n",
    "            new_y = np.stack((v_features, new_feature_vec), axis=1)\n",
    "        except:\n",
    "            new_y = np.concatenate((v_features, np.array([new_feature_vec]).T), axis=1)\n",
    "\n",
    "        data[\"venue\"].y = torch.tensor(new_y)\n",
    "    return\n",
    "    \n",
    "# print(data_het[\"author\"].y)\n",
    "# print(data_het[\"author\"].y.shape)\n",
    "# addFeature(data_het, type=\"author\")\n",
    "# print(data_het[\"author\"].y)\n",
    "# print(data_het[\"author\"].y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delFeature(data):\n",
    "    \"\"\"\n",
    "    Delete features in .y tensor. If .y has only one feature, set it to the same value.\n",
    "    :input:\n",
    "        data - het data\n",
    "        type - one of node types of AMiner, dtype=string, ex: \"author\"\n",
    "    :output: data features of a sertain type modified\n",
    "    \"\"\"    \n",
    "    if type == \"author\":\n",
    "        a_features = data[\"author\"].y.cpu().detach().numpy();\n",
    "        new_feature_vec = np.random.randint(0,7,len(a_features), dtype='int64')\n",
    "        new_y = np.stack((a_features, new_feature_vec), axis=1)\n",
    "        data[\"author\"].y = torch.tensor(new_y)\n",
    "\n",
    "    if type == \"venue\":\n",
    "        v_features = data[\"venue\"].y.cpu().detach().numpy();\n",
    "        new_feature_vec = np.random.randint(0,7,len(v_features), dtype='int64')\n",
    "        new_y = np.stack((v_features, new_feature_vec), axis=1)\n",
    "        data[\"venue\"].y = torch.tensor(new_y)\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcac22119d5d3fe9b7808e8a2b2b1fad943735cdeeeffec737ec21b4dfa5d54e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
