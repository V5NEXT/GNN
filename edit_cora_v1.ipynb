{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph creation and modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.data as data\n",
    "import torch_geometric.transforms as transforms\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a graph and pass it to Data object of pyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "len = 20;\n",
    "height = 10;\n",
    "embeddings = torch.rand((100, 2), dtype=torch.float) # 100 nodes with 16 embeddings (node features) length\n",
    "rows = np.random.choice(height, len)\n",
    "cols = np.random.choice(height, len)\n",
    "edges = torch.tensor([rows, cols])\n",
    "edges_attr = np.random.choice(3, len)\n",
    "ys = torch.rand((height)).round().long()\n",
    "\n",
    "#Pass it to PyG data object\n",
    "graph = data.Data(x=embeddings, edge_index=edges, edge_attr=edges_attr, y=ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KarateClub',\n",
       " 'TUDataset',\n",
       " 'GNNBenchmarkDataset',\n",
       " 'Planetoid',\n",
       " 'FakeDataset',\n",
       " 'FakeHeteroDataset',\n",
       " 'NELL',\n",
       " 'CitationFull',\n",
       " 'CoraFull',\n",
       " 'Coauthor',\n",
       " 'Amazon',\n",
       " 'PPI',\n",
       " 'Reddit',\n",
       " 'Reddit2',\n",
       " 'Flickr',\n",
       " 'Yelp',\n",
       " 'AmazonProducts',\n",
       " 'QM7b',\n",
       " 'QM9',\n",
       " 'MD17',\n",
       " 'ZINC',\n",
       " 'MoleculeNet',\n",
       " 'Entities',\n",
       " 'RelLinkPredDataset',\n",
       " 'GEDDataset',\n",
       " 'AttributedGraphDataset',\n",
       " 'MNISTSuperpixels',\n",
       " 'FAUST',\n",
       " 'DynamicFAUST',\n",
       " 'ShapeNet',\n",
       " 'ModelNet',\n",
       " 'CoMA',\n",
       " 'SHREC2016',\n",
       " 'TOSCA',\n",
       " 'PCPNetDataset',\n",
       " 'S3DIS',\n",
       " 'GeometricShapes',\n",
       " 'BitcoinOTC',\n",
       " 'ICEWS18',\n",
       " 'GDELT',\n",
       " 'DBP15K',\n",
       " 'WILLOWObjectClass',\n",
       " 'PascalVOCKeypoints',\n",
       " 'PascalPF',\n",
       " 'SNAPDataset',\n",
       " 'SuiteSparseMatrixCollection',\n",
       " 'AMiner',\n",
       " 'WordNet18',\n",
       " 'WordNet18RR',\n",
       " 'WikiCS',\n",
       " 'WebKB',\n",
       " 'WikipediaNetwork',\n",
       " 'Actor',\n",
       " 'OGB_MAG',\n",
       " 'DBLP',\n",
       " 'MovieLens',\n",
       " 'IMDB',\n",
       " 'LastFM',\n",
       " 'HGBDataset',\n",
       " 'JODIEDataset',\n",
       " 'MixHopSyntheticDataset',\n",
       " 'UPFD',\n",
       " 'GitHub',\n",
       " 'FacebookPagePage',\n",
       " 'LastFMAsia',\n",
       " 'DeezerEurope',\n",
       " 'GemsecDeezer',\n",
       " 'Twitch',\n",
       " 'Airports',\n",
       " 'BAShapes',\n",
       " 'MalNetTiny',\n",
       " 'OMDB',\n",
       " 'PolBlogs',\n",
       " 'EmailEUCore',\n",
       " 'StochasticBlockModelDataset',\n",
       " 'RandomPartitionGraphDataset',\n",
       " 'LINKXDataset',\n",
       " 'EllipticBitcoinDataset']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cora = data.Data(\"Cora\")\n",
    "# cora_path = \"D:/GNN/data/cora/raw/ind.cora.allx\";\n",
    "# with open(cora_path, 'rb') as f:\n",
    "#   text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cora Parameters**\n",
    "\n",
    "ind.cora.x : Training set node eigenvector , Save to ：scipy.sparse.csr.csr_matrix, The actual expanded size is ： (140, 1433)\n",
    "\n",
    "\n",
    "ind.cora.tx : Test set node eigenvector , Save to ：scipy.sparse.csr.csr_matrix, The actual expanded size is ： (1000, 1433)\n",
    "\n",
    "\n",
    "ind.cora.allx : The feature vectors of training nodes with labels and without labels , Save to ：scipy.sparse.csr.csr_matrix, The actual expanded size is ：(1708, 1433), It can be understood as a collection of node features other than the test set , The training set is a subset of it\n",
    "\n",
    "\n",
    "ind.cora.y : one-hot Represents the label of the training node , Save to ：numpy.ndarray\n",
    "\n",
    "\n",
    "ind.cora.ty : one-hot Represents the label of the test node , Save to ：numpy.ndarray\n",
    "\n",
    "\n",
    "ind.cora.ally : one-hot It means ind.cora.allx Corresponding label , Save to ：numpy.ndarray\n",
    "\n",
    "\n",
    "ind.cora.graph : Save information about the edges between nodes , Save in ：{ index : [ index_of_neighbor_nodes ] }\n",
    "\n",
    "\n",
    "ind.cora.test.index : Save the index of the test set node , Save to ：List, Used for the following inductive learning settings ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "import os.path as os\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = 'Cora'\n",
    "transform = T.Compose([\n",
    "    T.RandomNodeSplit(num_val=500, num_test=500),\n",
    "    T.TargetIndegree(),\n",
    "])\n",
    "path = \"D:/GNN/data/CoraTest/\"\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset=Planetoid(root=r\"./Cora2222\",name=\"Cora\") # root:  Specify the path  name:  Dataset name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13060/3940649457.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/GNN/Cora2222/Cora/raw/ind.cora.allx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\kateb\\anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36mmmread\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \"\"\"\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mMMFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kateb\\anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kateb\\anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36m_parse_header\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_parse_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymmetry\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m         self._init_attrs(rows=rows, cols=cols, entries=entries, format=format,\n\u001b[0;32m    501\u001b[0m                          field=field, symmetry=symmetry)\n",
      "\u001b[1;32mc:\\Users\\kateb\\anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36minfo\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;31m# read and validate header line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mmmid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymmetry\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m                 \u001b[1;33m[\u001b[0m\u001b[0masstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmmid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%%MatrixMarket'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 1)"
     ]
    }
   ],
   "source": [
    "# import scipy.io\n",
    "# scipy.io.mmread(\"D:/GNN/Cora2222/Cora/raw/ind.cora.allx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcac22119d5d3fe9b7808e8a2b2b1fad943735cdeeeffec737ec21b4dfa5d54e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
